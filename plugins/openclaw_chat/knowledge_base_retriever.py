#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çŸ¥è¯†åº“æ£€ç´¢ç®¡ç†å™¨
ä¼˜åŒ–æ£€ç´¢ç»“æœï¼Œå®ç°ç»“æœæ’åºå’Œè¿‡æ»¤ï¼Œæ·»åŠ æ£€ç´¢ç¼“å­˜
"""

import time
import hashlib
from typing import List, Dict, Optional, Any, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from collections import defaultdict
from nonebot.log import logger


@dataclass
class SearchCacheItem:
    """æ£€ç´¢ç¼“å­˜é¡¹"""

    query: str  # æŸ¥è¯¢æ–‡æœ¬
    kb_id: str  # çŸ¥è¯†åº“ ID
    results: List[Dict[str, Any]]  # æ£€ç´¢ç»“æœ
    timestamp: float  # æ—¶é—´æˆ³
    ttl: int = 300  # ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰

    def is_expired(self) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦è¿‡æœŸ

        Returns:
            bool: æ˜¯å¦è¿‡æœŸ
        """
        return time.time() - self.timestamp > self.ttl


@dataclass
class SearchContext:
    """æ£€ç´¢ä¸Šä¸‹æ–‡"""

    query: str  # æŸ¥è¯¢æ–‡æœ¬
    kb_id: str  # çŸ¥è¯†åº“ ID
    top_k: int = 3  # è¿”å›ç»“æœæ•°é‡
    min_score: float = 0.0  # æœ€å°ç›¸ä¼¼åº¦åˆ†æ•°
    filters: Optional[Dict[str, Any]] = None  # è¿‡æ»¤æ¡ä»¶
    sort_by: str = "score"  # æ’åºæ–¹å¼ï¼ˆscore/relevance/timeï¼‰
    use_cache: bool = True  # æ˜¯å¦ä½¿ç”¨ç¼“å­˜


class KnowledgeBaseRetriever:
    """çŸ¥è¯†åº“æ£€ç´¢ç®¡ç†å™¨"""

    def __init__(
        self,
        cache_ttl: int = 300,
        cache_size: int = 1000
    ):
        """
        åˆå§‹åŒ–çŸ¥è¯†åº“æ£€ç´¢ç®¡ç†å™¨

        Args:
            cache_ttl: ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤ 5 åˆ†é’Ÿï¼‰
            cache_size: ç¼“å­˜å¤§å°ï¼ˆé»˜è®¤ 1000ï¼‰
        """
        self.cache_ttl = cache_ttl
        self.cache_size = cache_size

        # ç¼“å­˜ï¼škey -> SearchCacheItem
        self._cache: Dict[str, SearchCacheItem] = {}

        # ç¼“å­˜è®¿é—®æ—¶é—´ï¼ˆç”¨äº LRUï¼‰
        self._cache_access_time: Dict[str, float] = {}

        # ç¼“å­˜å‘½ä¸­ç»Ÿè®¡
        self._cache_stats = {
            "hits": 0,
            "misses": 0,
            "evictions": 0
        }

        logger.info(f"âœ… çŸ¥è¯†åº“æ£€ç´¢ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸï¼ˆTTL: {cache_ttl}s, Size: {cache_size}ï¼‰")

    def _generate_cache_key(
        self,
        query: str,
        kb_id: str,
        top_k: int,
        filters: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        ç”Ÿæˆç¼“å­˜é”®

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            kb_id: çŸ¥è¯†åº“ ID
            top_k: è¿”å›ç»“æœæ•°é‡
            filters: è¿‡æ»¤æ¡ä»¶

        Returns:
            str: ç¼“å­˜é”®
        """
        # å°†å‚æ•°ç»„åˆæˆå­—ç¬¦ä¸²
        params = f"{query}:{kb_id}:{top_k}:{str(filters)}"

        # ç”Ÿæˆå“ˆå¸Œ
        return hashlib.md5(params.encode('utf-8')).hexdigest()

    def _get_from_cache(
        self,
        query: str,
        kb_id: str,
        top_k: int,
        filters: Optional[Dict[str, Any]] = None
    ) -> Optional[List[Dict[str, Any]]]:
        """
        ä»ç¼“å­˜è·å–ç»“æœ

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            kb_id: çŸ¥è¯†åº“ ID
            top_k: è¿”å›ç»“æœæ•°é‡
            filters: è¿‡æ»¤æ¡ä»¶

        Returns:
            List[Dict[str, Any]]: æ£€ç´¢ç»“æœï¼ˆç¼“å­˜æœªå‘½ä¸­åˆ™è¿”å› Noneï¼‰
        """
        cache_key = self._generate_cache_key(query, kb_id, top_k, filters)

        if cache_key not in self._cache:
            self._cache_stats["misses"] += 1
            return None

        cache_item = self._cache[cache_key]

        # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
        if cache_item.is_expired():
            # ç§»é™¤è¿‡æœŸé¡¹
            del self._cache[cache_key]
            self._cache_stats["misses"] += 1
            return None

        # æ›´æ–°è®¿é—®æ—¶é—´
        self._cache_access_time[cache_key] = time.time()
        self._cache_stats["hits"] += 1

        logger.debug(f"âœ… ç¼“å­˜å‘½ä¸­: {cache_key[:8]}...")

        return cache_item.results

    def _add_to_cache(
        self,
        query: str,
        kb_id: str,
        results: List[Dict[str, Any]],
        top_k: int = 3,
        filters: Optional[Dict[str, Any]] = None
    ):
        """
        æ·»åŠ ç»“æœåˆ°ç¼“å­˜

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            kb_id: çŸ¥è¯†åº“ ID
            results: æ£€ç´¢ç»“æœ
            top_k: è¿”å›ç»“æœæ•°é‡
            filters: è¿‡æ»¤æ¡ä»¶
        """
        # æ£€æŸ¥ç¼“å­˜å¤§å°
        if len(self._cache) >= self.cache_size:
            self._evict_lru()

        cache_key = self._generate_cache_key(query, kb_id, top_k, filters)

        # æ·»åŠ åˆ°ç¼“å­˜
        cache_item = SearchCacheItem(
            query=query,
            kb_id=kb_id,
            results=results,
            timestamp=time.time(),
            ttl=self.cache_ttl
        )

        self._cache[cache_key] = cache_item
        self._cache_access_time[cache_key] = time.time()

        logger.debug(f"âœ… æ·»åŠ åˆ°ç¼“å­˜: {cache_key[:8]}... (ç»“æœæ•°: {len(results)})")

    def _evict_lru(self):
        """ç§»é™¤æœ€ä¹…æœªä½¿ç”¨çš„ç¼“å­˜é¡¹ï¼ˆLRUï¼‰"""
        if not self._cache:
            return

        # æ‰¾åˆ°æœ€ä¹…æœªä½¿ç”¨çš„ç¼“å­˜é¡¹
        lru_key = min(self._cache_access_time, key=self._cache_access_time.get)

        # ç§»é™¤
        del self._cache[lru_key]
        del self._cache_access_time[lru_key]

        self._cache_stats["evictions"] += 1

        logger.debug(f"âœ… ç§»é™¤ LRU ç¼“å­˜é¡¹: {lru_key[:8]}...")

    # ========== æ£€ç´¢ä¼˜åŒ– ==========

    def post_process_results(
        self,
        results: List[Dict[str, Any]],
        context: SearchContext
    ) -> List[Dict[str, Any]]:
        """
        åå¤„ç†æ£€ç´¢ç»“æœ

        Args:
            results: åŸå§‹æ£€ç´¢ç»“æœ
            context: æ£€ç´¢ä¸Šä¸‹æ–‡

        Returns:
            List[Dict[str, Any]]: å¤„ç†åçš„ç»“æœ
        """
        if not results:
            return []

        # 1. è¿‡æ»¤
        filtered_results = self._filter_results(results, context)

        # 2. æ’åº
        sorted_results = self._sort_results(filtered_results, context)

        # 3. é™åˆ¶æ•°é‡
        limited_results = sorted_results[:context.top_k]

        # 4. å»é‡
        deduplicated_results = self._deduplicate_results(limited_results)

        return deduplicated_results

    def _filter_results(
        self,
        results: List[Dict[str, Any]],
        context: SearchContext
    ) -> List[Dict[str, Any]]:
        """
        è¿‡æ»¤æ£€ç´¢ç»“æœ

        Args:
            results: åŸå§‹æ£€ç´¢ç»“æœ
            context: æ£€ç´¢ä¸Šä¸‹æ–‡

        Returns:
            List[Dict[str, Any]]: è¿‡æ»¤åçš„ç»“æœ
        """
        filtered = []

        for result in results:
            # æ£€æŸ¥æœ€å°åˆ†æ•°
            if result.get("score") and result["score"] < context.min_score:
                continue

            # æ£€æŸ¥è‡ªå®šä¹‰è¿‡æ»¤æ¡ä»¶
            if context.filters:
                if not self._match_filters(result, context.filters):
                    continue

            filtered.append(result)

        logger.debug(f"âœ… è¿‡æ»¤ç»“æœ: {len(results)} -> {len(filtered)}")

        return filtered

    def _match_filters(
        self,
        result: Dict[str, Any],
        filters: Dict[str, Any]
    ) -> bool:
        """
        åŒ¹é…è¿‡æ»¤æ¡ä»¶

        Args:
            result: æ£€ç´¢ç»“æœ
            filters: è¿‡æ»¤æ¡ä»¶

        Returns:
            bool: æ˜¯å¦åŒ¹é…
        """
        metadata = result.get("metadata", {})

        for key, value in filters.items():
            if key not in metadata:
                return False

            if metadata[key] != value:
                return False

        return True

    def _sort_results(
        self,
        results: List[Dict[str, Any]],
        context: SearchContext
    ) -> List[Dict[str, Any]]:
        """
        æ’åºæ£€ç´¢ç»“æœ

        Args:
            results: æ£€ç´¢ç»“æœ
            context: æ£€ç´¢ä¸Šä¸‹æ–‡

        Returns:
            List[Dict[str, Any]]: æ’åºåçš„ç»“æœ
        """
        if context.sort_by == "score":
            # æŒ‰ç›¸ä¼¼åº¦åˆ†æ•°æ’åºï¼ˆå‡åºï¼‰
            return sorted(results, key=lambda x: x.get("score", float('inf')))

        elif context.sort_by == "relevance":
            # æŒ‰ç›¸å…³æ€§æ’åºï¼ˆè€ƒè™‘å¤šä¸ªå› ç´ ï¼‰
            return sorted(
                results,
                key=lambda x: self._calculate_relevance(x, context.query)
            )

        else:
            # é»˜è®¤æŒ‰åˆ†æ•°æ’åº
            return results

    def _calculate_relevance(
        self,
        result: Dict[str, Any],
        query: str
    ) -> float:
        """
        è®¡ç®—ç›¸å…³æ€§åˆ†æ•°

        Args:
            result: æ£€ç´¢ç»“æœ
            query: æŸ¥è¯¢æ–‡æœ¬

        Returns:
            float: ç›¸å…³æ€§åˆ†æ•°ï¼ˆè¶Šä½è¶Šç›¸å…³ï¼‰
        """
        # åŸºç¡€åˆ†æ•°ï¼ˆç›¸ä¼¼åº¦ï¼‰
        score = result.get("score", 1.0)

        # æ–‡æœ¬é•¿åº¦å› å­ï¼ˆè¶ŠçŸ­è¶Šç›¸å…³ï¼‰
        text_length = len(result.get("text", ""))
        length_factor = text_length / 1000.0  # å½’ä¸€åŒ–

        # å…³é”®è¯åŒ¹é…å› å­
        keywords = query.split()
        text = result.get("text", "").lower()

        keyword_matches = sum(1 for keyword in keywords if keyword.lower() in text)
        keyword_factor = 1.0 - (keyword_matches / len(keywords)) if keywords else 0.0

        # ç»¼åˆåˆ†æ•°
        relevance = score * (1.0 + length_factor) * (1.0 + keyword_factor)

        return relevance

    def _deduplicate_results(
        self,
        results: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        å»é‡æ£€ç´¢ç»“æœ

        Args:
            results: æ£€ç´¢ç»“æœ

        Returns:
            List[Dict[str, Any]]: å»é‡åçš„ç»“æœ
        """
        seen = set()
        deduplicated = []

        for result in results:
            # ä½¿ç”¨æ–‡æœ¬ä½œä¸ºå»é‡ä¾æ®
            text = result.get("text", "")

            if text not in seen:
                seen.add(text)
                deduplicated.append(result)

        logger.debug(f"âœ… å»é‡ç»“æœ: {len(results)} -> {len(deduplicated)}")

        return deduplicated

    # ========== æ£€ç´¢æ¥å£ ==========

    async def retrieve(
        self,
        vector_db,
        context: SearchContext
    ) -> List[Dict[str, Any]]:
        """
        æ£€ç´¢çŸ¥è¯†åº“

        Args:
            vector_db: å‘é‡æ•°æ®åº“ç®¡ç†å™¨
            context: æ£€ç´¢ä¸Šä¸‹æ–‡

        Returns:
            List[Dict[str, Any]]: æ£€ç´¢ç»“æœ
        """
        # æ£€æŸ¥ç¼“å­˜
        if context.use_cache:
            cached_results = self._get_from_cache(
                query=context.query,
                kb_id=context.kb_id,
                top_k=context.top_k,
                filters=context.filters
            )

            if cached_results is not None:
                logger.info(f"âœ… ç¼“å­˜å‘½ä¸­: {context.kb_id}")
                return cached_results

        # æ‰§è¡Œæ£€ç´¢
        logger.info(f"ğŸ” æ£€ç´¢çŸ¥è¯†åº“: {context.kb_id}")

        # æ„å»ºå…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶
        where = None
        if context.filters:
            where = context.filters

        # è°ƒç”¨å‘é‡æ•°æ®åº“æœç´¢
        raw_results = vector_db.search(
            kb_id=context.kb_id,
            query=context.query,
            top_k=context.top_k * 2,  # è·å–æ›´å¤šç»“æœï¼Œåå¤„ç†åç­›é€‰
            where=where
        )

        # åå¤„ç†
        processed_results = self.post_process_results(raw_results, context)

        # æ·»åŠ åˆ°ç¼“å­˜
        if context.use_cache:
            self._add_to_cache(
                query=context.query,
                kb_id=context.kb_id,
                results=processed_results,
                top_k=context.top_k,
                filters=context.filters
            )

        logger.info(f"âœ… æ£€ç´¢å®Œæˆ: {len(processed_results)} ä¸ªç»“æœ")

        return processed_results

    # ========== ç¼“å­˜ç®¡ç† ==========

    def clear_cache(self, kb_id: Optional[str] = None):
        """
        æ¸…ç©ºç¼“å­˜

        Args:
            kb_id: çŸ¥è¯†åº“ IDï¼ˆNone åˆ™æ¸…ç©ºæ‰€æœ‰ï¼‰
        """
        if kb_id is None:
            # æ¸…ç©ºæ‰€æœ‰ç¼“å­˜
            self._cache.clear()
            self._cache_access_time.clear()
            logger.info("âœ… æ¸…ç©ºæ‰€æœ‰ç¼“å­˜")
        else:
            # æ¸…ç©ºæŒ‡å®šçŸ¥è¯†åº“çš„ç¼“å­˜
            keys_to_remove = [
                key for key, item in self._cache.items()
                if item.kb_id == kb_id
            ]

            for key in keys_to_remove:
                del self._cache[key]
                if key in self._cache_access_time:
                    del self._cache_access_time[key]

            logger.info(f"âœ… æ¸…ç©ºç¼“å­˜: {kb_id} ({len(keys_to_remove)} é¡¹)")

    def get_cache_stats(self) -> Dict[str, Any]:
        """
        è·å–ç¼“å­˜ç»Ÿè®¡

        Returns:
            Dict[str, Any]: ç¼“å­˜ç»Ÿè®¡
        """
        hit_rate = 0.0

        total_requests = self._cache_stats["hits"] + self._cache_stats["misses"]
        if total_requests > 0:
            hit_rate = self._cache_stats["hits"] / total_requests

        return {
            "size": len(self._cache),
            "max_size": self.cache_size,
            "hits": self._cache_stats["hits"],
            "misses": self._cache_stats["misses"],
            "evictions": self._cache_stats["evictions"],
            "hit_rate": hit_rate,
            "ttl": self.cache_ttl
        }

    def print_cache_stats(self) -> str:
        """
        æ‰“å°ç¼“å­˜ç»Ÿè®¡

        Returns:
            str: ç¼“å­˜ç»Ÿè®¡æ–‡æœ¬
        """
        stats = self.get_cache_stats()

        lines = [
            "ğŸ“Š ç¼“å­˜ç»Ÿè®¡",
            "=" * 30,
            f"ç¼“å­˜å¤§å°: {stats['size']}/{stats['max_size']}",
            f"å‘½ä¸­æ¬¡æ•°: {stats['hits']}",
            f"æœªå‘½ä¸­æ¬¡æ•°: {stats['misses']}",
            f"æ·˜æ±°æ¬¡æ•°: {stats['evictions']}",
            f"å‘½ä¸­ç‡: {stats['hit_rate']:.2%}",
            f"TTL: {stats['ttl']}ç§’"
        ]

        return "\n".join(lines)
