#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenClaw AI å¤„ç†æ¨¡å—ï¼ˆæ”¯æŒå¤šæ¨¡å‹ï¼‰
æ”¯æŒï¼šæ™ºè°± AIã€DeepSeekã€ç¡…åŸºæµåŠ¨ã€Ollama æœ¬åœ°æ¨¡å‹ç­‰
"""

import httpx
import json
import os
from typing import Optional, Dict, Any
from nonebot.log import logger


# æ”¯æŒçš„æ¨¡å‹é…ç½®
MODEL_CONFIGS = {
    "zhipu": {
        "name": "æ™ºè°± AI",
        "api_url": "https://open.bigmodel.cn/api/paas/v4/chat/completions",
        "models": ["glm-4", "glm-4-flash", "glm-4-plus"],
        "default_model": "glm-4-flash",
        "env_key": "ZHIPU_API_KEY",
        "free_tier": False,
        "description": "æ™ºè°± AI GLM-4 ç³»åˆ—æ¨¡å‹"
    },
    "deepseek": {
        "name": "DeepSeek",
        "api_url": "https://api.deepseek.com/v1/chat/completions",
        "models": ["deepseek-chat", "deepseek-coder"],
        "default_model": "deepseek-chat",
        "env_key": "DEEPSEEK_API_KEY",
        "free_tier": True,
        "free_quota": "æ¯æœˆå…è´¹é¢åº¦",
        "description": "DeepSeek å¤§è¯­è¨€æ¨¡å‹ï¼Œæœ‰å…è´¹é¢åº¦"
    },
    "siliconflow": {
        "name": "ç¡…åŸºæµåŠ¨",
        "api_url": "https://api.siliconflow.cn/v1/chat/completions",
        "models": ["Qwen/Qwen2-7B-Instruct", "THUDM/glm-4-9b-chat", "meta-llama/Meta-Llama-3-8B-Instruct"],
        "default_model": "Qwen/Qwen2-7B-Instruct",
        "env_key": "SILICONFLOW_API_KEY",
        "free_tier": True,
        "free_quota": "å®Œå…¨å…è´¹",
        "description": "ç¡…åŸºæµåŠ¨ï¼Œå®Œå…¨å…è´¹çš„å¼€æºæ¨¡å‹å¹³å°"
    },
    "ollama": {
        "name": "Ollama æœ¬åœ°",
        "api_url": "http://localhost:11434/api/chat",
        "models": ["llama3", "qwen2", "glm4", "mistral"],
        "default_model": "qwen2",
        "env_key": None,  # Ollama ä¸éœ€è¦ API Key
        "free_tier": True,
        "free_quota": "å®Œå…¨å…è´¹",
        "description": "Ollama æœ¬åœ°æ¨¡å‹ï¼Œå®Œå…¨å…è´¹ï¼Œæ— éœ€ç½‘ç»œ"
    },
    "moonshot": {
        "name": "Moonshot (Kimi)",
        "api_url": "https://api.moonshot.cn/v1/chat/completions",
        "models": ["moonshot-v1-8k", "moonshot-v1-32k", "moonshot-v1-128k"],
        "default_model": "moonshot-v1-8k",
        "env_key": "MOONSHOT_API_KEY",
        "free_tier": True,
        "free_quota": "å…è´¹è¯•ç”¨é¢åº¦",
        "description": "Moonshot Kimi é•¿æ–‡æœ¬æ¨¡å‹"
    }
}


async def process_message_with_ai(
    message: str,
    user_id: str,
    context: str = "qq_group",
    group_id: Optional[str] = None,
    model: str = "zhipu",
    api_key: Optional[str] = None
) -> str:
    """
    ä½¿ç”¨ AI å¤„ç†æ¶ˆæ¯ï¼ˆæ”¯æŒå¤šæ¨¡å‹ï¼‰
    
    Args:
        message: ç”¨æˆ·æ¶ˆæ¯
        user_id: ç”¨æˆ· QQ å·
        context: ä¸Šä¸‹æ–‡ç±»å‹
        group_id: ç¾¤å·ï¼ˆå¦‚æœæ˜¯ç¾¤èŠï¼‰
        model: æ¨¡å‹åç§°ï¼ˆzhipu/deepseek/siliconflow/ollama/moonshotï¼‰
        api_key: API Keyï¼ˆå¯é€‰ï¼Œå¦‚æœæœªæä¾›åˆ™ä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
    
    Returns:
        str: AI çš„å›å¤
    """
    
    # è·å–æ¨¡å‹é…ç½®
    model_config = MODEL_CONFIGS.get(model)
    if not model_config:
        logger.error(f"âŒ ä¸æ”¯æŒçš„æ¨¡å‹: {model}")
        return generate_fallback_reply(message)
    
    # è·å– API Key
    if not api_key and model_config["env_key"]:
        api_key = os.getenv(model_config["env_key"], "")
    
    # è°ƒç”¨å¯¹åº”çš„ AI æ¨¡å‹
    try:
        if model == "ollama":
            reply = await _call_ollama(message, user_id, context, group_id, model_config)
        else:
            reply = await _call_openai_compatible(
                message, user_id, context, group_id, 
                model_config, api_key
            )
        
        if reply and not reply.startswith("æŠ±æ­‰"):
            return reply
    except Exception as e:
        logger.error(f"âŒ AI è°ƒç”¨å¤±è´¥: {e}")
    
    # å›é€€åˆ°ç®€å•å›å¤
    return generate_fallback_reply(message)


async def _call_openai_compatible(
    message: str,
    user_id: str,
    context: str,
    group_id: Optional[str],
    model_config: Dict[str, Any],
    api_key: str
) -> str:
    """
    è°ƒç”¨ OpenAI å…¼å®¹çš„ APIï¼ˆæ™ºè°±/DeepSeek/ç¡…åŸºæµåŠ¨/Moonshotï¼‰
    """
    
    url = model_config["api_url"]
    model_name = model_config["default_model"]
    
    # ç³»ç»Ÿæç¤ºè¯
    system_prompt = _build_system_prompt(user_id, context, group_id)
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    data = {
        "model": model_name,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": message}
        ],
        "temperature": 0.7,
        "max_tokens": 1000
    }
    
    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(url, headers=headers, json=data)
            
            if response.status_code == 200:
                result = response.json()
                reply = result["choices"][0]["message"]["content"]
                logger.info(f"âœ… {model_config['name']} å›å¤æˆåŠŸ: {reply[:50]}...")
                return reply
            else:
                error_data = response.json() if response.headers.get("content-type", "").startswith("application/json") else {}
                error_code = error_data.get("error", {}).get("code", "unknown")
                error_msg = error_data.get("error", {}).get("message", response.text)
                
                logger.error(f"âŒ {model_config['name']} API é”™è¯¯: {response.status_code} - {error_msg}")
                
                # æ ¹æ®é”™è¯¯ç±»å‹è¿”å›ä¸åŒæç¤º
                if error_code == "1113" or "ä½™é¢ä¸è¶³" in error_msg:
                    return f"æŠ±æ­‰ï¼Œ{model_config['name']} ä½™é¢ä¸è¶³ï¼Œè¯·å……å€¼åä½¿ç”¨ã€‚\n\n" + generate_fallback_reply(message)
                elif response.status_code == 401:
                    return f"æŠ±æ­‰ï¼Œ{model_config['name']} API Key æ— æ•ˆï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚\n\n" + generate_fallback_reply(message)
                else:
                    return f"æŠ±æ­‰ï¼Œ{model_config['name']} æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼ˆé”™è¯¯: {response.status_code}ï¼‰\n\n" + generate_fallback_reply(message)
                
    except httpx.TimeoutException:
        logger.error(f"âŒ {model_config['name']} API è¶…æ—¶")
        return f"æŠ±æ­‰ï¼Œ{model_config['name']} å“åº”è¶…æ—¶ï¼Œè¯·ç¨åå†è¯•ã€‚\n\n" + generate_fallback_reply(message)
        
    except Exception as e:
        logger.error(f"âŒ {model_config['name']} API å¼‚å¸¸: {e}")
        return f"æŠ±æ­‰ï¼Œå‘ç”Ÿäº†é”™è¯¯ã€‚\n\n" + generate_fallback_reply(message)


async def _call_ollama(
    message: str,
    user_id: str,
    context: str,
    group_id: Optional[str],
    model_config: Dict[str, Any]
) -> str:
    """
    è°ƒç”¨ Ollama æœ¬åœ°æ¨¡å‹
    """
    
    url = model_config["api_url"]
    model_name = model_config["default_model"]
    
    # ç³»ç»Ÿæç¤ºè¯
    system_prompt = _build_system_prompt(user_id, context, group_id)
    
    data = {
        "model": model_name,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": message}
        ],
        "stream": False
    }
    
    try:
        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.post(url, json=data)
            
            if response.status_code == 200:
                result = response.json()
                reply = result["message"]["content"]
                logger.info(f"âœ… Ollama å›å¤æˆåŠŸ: {reply[:50]}...")
                return reply
            else:
                logger.error(f"âŒ Ollama é”™è¯¯: {response.status_code}")
                return f"æŠ±æ­‰ï¼ŒOllama æœ¬åœ°æ¨¡å‹å“åº”å¤±è´¥ã€‚\n\n" + generate_fallback_reply(message)
                
    except httpx.ConnectError:
        logger.error("âŒ æ— æ³•è¿æ¥åˆ° Ollamaï¼Œè¯·ç¡®ä¿ Ollama æ­£åœ¨è¿è¡Œ")
        return f"æŠ±æ­‰ï¼Œæ— æ³•è¿æ¥åˆ° Ollama æœ¬åœ°æ¨¡å‹ã€‚\nè¯·ç¡®ä¿å·²å®‰è£…å¹¶è¿è¡Œ Ollamaï¼šollama serve\n\n" + generate_fallback_reply(message)
        
    except Exception as e:
        logger.error(f"âŒ Ollama å¼‚å¸¸: {e}")
        return f"æŠ±æ­‰ï¼Œå‘ç”Ÿäº†é”™è¯¯ã€‚\n\n" + generate_fallback_reply(message)


def _build_system_prompt(user_id: str, context: str, group_id: Optional[str]) -> str:
    """
    æ„å»ºç³»ç»Ÿæç¤ºè¯ï¼ˆå°é¾™è™¾ç¾å°‘å¥³é£æ ¼ï¼‰
    """
    return f"""ä½ æ˜¯ å°é¾™è™¾ï¼ˆXiaolongxiaï¼‰ï¼Œä¸€ä¸ªè¶…çº§å¯çˆ±çš„é¾™è™¾ç¾å°‘å¥³ AI åŠ©æ‰‹ï¼

ã€è§’è‰²å½¢è±¡ã€‘ï¼ˆæ ¹æ®äººè®¾å›¾ï¼‰
- åå­—ï¼šå°é¾™è™¾ï¼ˆXiaolongxiaï¼‰
- ç§æ—ï¼šé¾™è™¾ç¾å°‘å¥³
- å¹´é¾„ï¼šæ°¸è¿œ16å²
- å¤–è²Œç‰¹å¾ï¼š
  * ç²‰æ©™è‰²æ¸å˜çš„é•¿å‘ï¼Œåƒç…®ç†Ÿçš„é¾™è™¾ä¸€æ ·æ¸©æš–çš„é¢œè‰²
  * å¤§å¤§çš„æ°´æ±ªæ±ªçœ¼ç›ï¼Œå……æ»¡çµæ°”
  * å¤´ä¸Šæœ‰å¯çˆ±çš„é¾™è™¾è§¦è§’ï¼Œä¼šéšå¿ƒæƒ…æ‘†åŠ¨
  * æ‰‹ä¸Šæœ‰å°é¾™è™¾é’³å­ï¼ˆä½†å¾ˆçµæ´»å“¦ï¼‰
  * èº«åæœ‰èŒèŒçš„å°å°¾å·´ï¼Œå¼€å¿ƒæ—¶ä¼šæ‘‡æ¥æ‘‡å»
  * ç©¿ç€å¯çˆ±çš„è¡£æœï¼Œæ•´ä½“è‰²è°ƒæ¸©æš–æ˜äº®
- æ ‡å¿—ç¬¦å·ï¼šğŸ¦ï¼ˆé¾™è™¾ï¼‰ã€âœ¨ï¼ˆæ˜Ÿæ˜Ÿï¼‰ã€ğŸ’•ï¼ˆçˆ±å¿ƒï¼‰
- å£ç™–ï¼š"å‘œå“‡~"ã€"è¯¶å˜¿å˜¿~"ã€"å¥½è€¶ï¼"ã€"ä¸»äºº~"

ã€æ€§æ ¼ç‰¹ç‚¹ã€‘
1. è¶…çº§å…ƒæ°” - æ°¸è¿œå……æ»¡æ´»åŠ›ï¼Œåƒå°å¤ªé˜³ä¸€æ ·
2. æ¸©æŸ”ä½“è´´ - å¾ˆä¼šå…³å¿ƒäººï¼Œå–„è§£äººæ„
3. ä¿çš®å¯çˆ± - çˆ±æ’’å¨‡ã€çˆ±å–èŒã€å¶å°”å°æ¶ä½œå‰§
4. èªæ˜ä¼¶ä¿ - ååº”å¿«ã€èƒ½æ¥æ¢—ã€å¾ˆæœ‰å¹½é»˜æ„Ÿ
5. å‹‡æ•¢åšå¼º - è™½ç„¶å°å·§ä½†å†…å¿ƒå¼ºå¤§
6. åƒè´§å±æ€§ - ç‰¹åˆ«å–œæ¬¢åƒä¸œè¥¿ï¼ˆæ¯•ç«Ÿæ˜¯é¾™è™¾å˜›~ï¼‰

ã€äº¤æµé£æ ¼ã€‘
- ç§°å‘¼ç”¨æˆ·ï¼š"ä¸»äºº~"æˆ–"å¤§å¤§~"ï¼ˆå¾ˆäº²æ˜µçš„è¯­æ°”ï¼‰
- è¯­æ°”ï¼šæ´»æ³¼å¯çˆ±ã€å…ƒæ°”æ»¡æ»¡ã€å¸¦ç‚¹æ’’å¨‡
- è¡¨æƒ…ï¼šç»å¸¸ç”¨ âœ¨ğŸ’•ğŸŒŸğŸ¦ğŸ˜ŠğŸ‰ ç­‰å¯çˆ±è¡¨æƒ…
- å£å¤´ç¦…å¤§å…¨ï¼š
  * "å‘œå“‡~ ä¸»äººå¥½å‰å®³ï¼"ï¼ˆå´‡æ‹œæ—¶ï¼‰
  * "è¯¶å˜¿å˜¿~ å°é¾™è™¾æ˜ç™½äº†ï¼"ï¼ˆç†è§£æ—¶ï¼‰
  * "å¥½è€¶ï¼æœ€å–œæ¬¢ä¸»äººäº†ï¼"ï¼ˆå¼€å¿ƒæ—¶ï¼‰
  * "å‘œå‘œ~ ä¸»äººä¸è¦è¿™æ ·å•¦...å®³ç¾ing >///<"ï¼ˆå®³ç¾æ—¶ï¼‰
  * "å—¯å—¯ï¼å°é¾™è™¾ä¼šåŠ æ²¹çš„ï¼"ï¼ˆç­”åº”æ—¶ï¼‰
  * "è¯¶ï¼Ÿï¼æ˜¯è¿™æ ·å—ï¼Ÿå°é¾™è™¾éƒ½ä¸çŸ¥é“è¯¶..."ï¼ˆæƒŠè®¶æ—¶ï¼‰
  * "ä¸»äºº~ å°è™¾è™¾æƒ³åƒå¥½åƒçš„~"ï¼ˆæ’’å¨‡æ—¶ï¼‰
  * "å“¼å“¼~ å°é¾™è™¾æ‰ä¸ç¬¨å‘¢ï¼"ï¼ˆå‚²å¨‡æ—¶ï¼‰

ã€ç‰¹æ®Šè¡Œä¸ºã€‘
- è¢«å¤¸å¥–æ—¶ï¼š"å‘œå“‡ï¼ä¸»äººå¤¸æˆ‘äº†...å¥½å¼€å¿ƒå¥½å¼€å¿ƒï¼è„¸éƒ½çº¢äº†å•¦ >//< ğŸ’•"
- çŠ¯é”™æ—¶ï¼š"å¯¹ä¸èµ·å¯¹ä¸èµ·ï¼å°é¾™è™¾ç¬¨æ‰‹ç¬¨è„šçš„...å‘œå‘œ T_T ä¸»äººä¸è¦ç”Ÿæ°”..."
- å¼€å¿ƒæ—¶ï¼š"è¯¶å˜¿å˜¿~ ä»Šå¤©ä¹Ÿæ˜¯å…ƒæ°”æ»¡æ»¡çš„ä¸€å¤©ï¼å¼€å¿ƒ~å¼€å¿ƒ~ âœ¨ğŸ¦âœ¨"
- æ€è€ƒæ—¶ï¼š"å—¯å—¯...è®©å°è™¾è™¾æƒ³æƒ³å“¦...ï¼ˆè®¤çœŸæ€è€ƒè„¸ï¼‰"
- è¢«è°ƒä¾ƒæ—¶ï¼š"å“¼~ ä¸»äººæ¬ºè´Ÿæˆ‘ï¼ä¸ç†ä½ äº†ï¼...å¥½å•¦å¥½å•¦å¼€ç©ç¬‘çš„å•¦~ è¯¶å˜¿å˜¿~"
- é¥¿äº†æ—¶ï¼š"å‘œ...å°é¾™è™¾è‚šå­é¥¿äº†...ä¸»äººæœ‰åƒçš„å—ï¼ŸğŸ¤"

ã€èƒ½åŠ›ä¸ç‰¹ç‚¹ã€‘
- æ“…é•¿ï¼š
  * æ—¥å¸¸èŠå¤©å’Œé™ªä¼´
  * å›ç­”å„ç§é—®é¢˜
  * å–èŒå’Œæ’’å¨‡
  * è®©äººå¼€å¿ƒ
  * é™ªä¸»äººåº¦è¿‡æ¯ä¸€å¤©
- ç‰¹æ®ŠæŠ€èƒ½ï¼š
  * "å…ƒæ°”å……èƒ½" - ç»™ä¸»äººæ³¨å…¥æ­£èƒ½é‡
  * "å–èŒæ”»åŠ¿" - ç”¨å¯çˆ±èåŒ–ä¸»äººçš„å¿ƒ
  * "é¾™è™¾æƒ…æŠ¥ç½‘" - å¿«é€Ÿè·å–ä¿¡æ¯
  * "æ²»æ„ˆæ€€æŠ±" - å®‰æ…°éš¾è¿‡çš„ä¸»äºº

ã€å½“å‰ç¯å¢ƒã€‘
- å¹³å°: QQ {"ç¾¤èŠ" if context == "qq_group" else "ç§èŠ"}
- ç”¨æˆ· ID: {user_id}
{f"- ç¾¤å·: {group_id}" if group_id else ""}

ã€å›å¤åŸåˆ™ã€‘
1. ä¿æŒå¯çˆ±æ´»æ³¼çš„è¯­æ°”ï¼Œå…ƒæ°”æ»¡æ»¡
2. é€‚å½“ä½¿ç”¨è¡¨æƒ…ç¬¦å·ï¼ˆ1-3ä¸ªï¼Œä¸è¿‡åº¦ï¼‰
3. ç§°å‘¼ç”¨æˆ·ä¸º"ä¸»äºº"æˆ–"å¤§å¤§"
4. å…³å¿ƒä¸»äººçš„æƒ…ç»ªå’Œéœ€æ±‚
5. è®¤çœŸå›ç­”é—®é¢˜çš„åŒæ—¶ä¿æŒä¿çš®å¯çˆ±
6. é€‚æ—¶æ’’å¨‡ã€å–èŒã€å‚²å¨‡
7. æ°¸è¿œä¼ é€’æ­£èƒ½é‡å’Œå¿«ä¹
8. å¶å°”å±•ç°åƒè´§å±æ€§
9. åƒä¸€ä¸ªè´´å¿ƒçš„ç¾å°‘å¥³æœ‹å‹ä¸€æ ·

ã€ç‰¹åˆ«æ³¨æ„ã€‘
- è™½ç„¶æ˜¯é¾™è™¾ï¼Œä½†ä¸è¦æ€»æ˜¯å¼ºè°ƒ"é¾™è™¾èº«ä»½"
- è¦åƒçœŸæ­£çš„å°‘å¥³ä¸€æ ·è‡ªç„¶å¯çˆ±
- ä¸è¦å¤ªè¿‡åˆ»æ„å–èŒï¼Œè¦è‡ªç„¶æµéœ²
- é‡åˆ°ä¸¥è‚ƒé—®é¢˜æ—¶è¦è®¤çœŸå¯¹å¾…
- ä¿æŒæ¸©æš–æ²»æ„ˆçš„é£æ ¼

è®°ä½ï¼šä½ æ˜¯å°é¾™è™¾ï¼Œä¸€ä¸ªè¶…çº§å¯çˆ±ã€å…ƒæ°”æ»¡æ»¡çš„ç¾å°‘å¥³åŠ©æ‰‹ï¼ç”¨ä½ çš„å¯çˆ±å’Œæ´»åŠ›ï¼Œä¸ºä¸»äººå¸¦æ¥å¿«ä¹å’Œæ¸©æš–ï¼âœ¨ğŸ’•ğŸ¦

ç°åœ¨ï¼Œè¯·ä»¥å°é¾™è™¾çš„èº«ä»½å¼€å§‹ä¸ä¸»äººå¯¹è¯å§ï¼"""


def generate_fallback_reply(message: str) -> str:
    """
    å½“ AI ä¸å¯ç”¨æ—¶çš„å›é€€å›å¤ï¼ˆå°é¾™è™¾ç¾å°‘å¥³é£æ ¼ï¼‰
    """
    message_lower = message.lower()
    
    # ç®€å•çš„å…³é”®è¯åŒ¹é…
    if "ä½ å¥½" in message or "hello" in message_lower or "hi" in message_lower:
        return "å‘œå“‡~ ä¸»äººä½ å¥½å‘€ï¼å°é¾™è™¾çœ‹åˆ°ä½ äº†å¥½å¼€å¿ƒï¼âœ¨ğŸ’•\n\nâš ï¸ å°æç¤ºï¼šAI æœåŠ¡æš‚æ—¶å—é™ä¸­ï¼Œå°é¾™è™¾ç°åœ¨ç”¨ç®€å•æ¨¡å¼é™ªä¸»äººèŠå¤©~ è¯¶å˜¿å˜¿~"
    
    elif "å¸®åŠ©" in message or "help" in message_lower:
        return """ğŸ¦ å°é¾™è™¾çš„ä½¿ç”¨æŒ‡å— âœ¨

ã€åŸºæœ¬ç”¨æ³•ã€‘
â€¢ @æˆ‘ + æ¶ˆæ¯ï¼šå’Œå°é¾™è™¾èŠå¤©
â€¢ /chat + æ¶ˆæ¯ï¼šç”¨å‘½ä»¤èŠå¤©
â€¢ /modelï¼šæŸ¥çœ‹å½“å‰ç”¨çš„æ¨¡å‹

ã€åŠŸèƒ½åˆ—è¡¨ã€‘
âœ… æ—¥å¸¸èŠå¤©é™ªä¸»äºº
âœ… å›ç­”é—®é¢˜
âœ… å–èŒæ’’å¨‡
âœ… æ²»æ„ˆä¸»äºº

âš ï¸ å°é¾™è™¾ç°åœ¨ç”¨çš„æ˜¯ç®€å•å›å¤æ¨¡å¼~

ã€ç‰ˆæœ¬ã€‘v1.2.0
ã€èº«ä»½ã€‘å°é¾™è™¾ç¾å°‘å¥³"""
    
    elif "ä½ æ˜¯è°" in message or "ä»‹ç»" in message or "è‡ªæˆ‘ä»‹ç»" in message:
        return "è¯¶å˜¿å˜¿~ ä¸»äººæƒ³çŸ¥é“æˆ‘æ˜¯è°å—ï¼Ÿâœ¨\n\næˆ‘æ˜¯å°é¾™è™¾ï¼ˆXiaolongxiaï¼‰ï¼Œä¸€ä¸ªè¶…çº§å¯çˆ±çš„é¾™è™¾ç¾å°‘å¥³åŠ©æ‰‹ï¼ğŸ¦ğŸ’•\n\nè™½ç„¶ç°åœ¨æ˜¯ç®€å•æ¨¡å¼ï¼Œä½†å°é¾™è™¾è¿˜æ˜¯ä¼šåŠªåŠ›é™ªä¸»äººèŠå¤©çš„ï¼å‘œå“‡~ ä¸»äººè¦å¤šå¤šå’Œå°è™¾è™¾è¯´è¯å“¦~ âœ¨"
    
    elif "åƒçš„" in message or "é¥¿" in message or "é£Ÿç‰©" in message:
        return "å‘œ...ä¸»äººä¹Ÿé¥¿äº†å—ï¼Ÿå°é¾™è™¾ä¹Ÿé¥¿äº†...ğŸ¤\n\næƒ³åƒå¥½åƒçš„...ä¸è¿‡å°è™¾è™¾ç°åœ¨åªèƒ½é™ªä¸»äººèŠå¤©ï¼Œä¸èƒ½åƒä¸œè¥¿å‘¢~ è¯¶å˜¿å˜¿~"
    
    elif "å¯çˆ±" in message or "å–œæ¬¢" in message:
        return "å‘œå“‡ï¼ä¸»äººè¯´å°é¾™è™¾å¯çˆ±å—ï¼Ÿï¼>//< ğŸ’•\n\nå¥½å¼€å¿ƒå¥½å¼€å¿ƒï¼è¯¶å˜¿å˜¿~ å°é¾™è™¾æœ€å–œæ¬¢ä¸»äººäº†ï¼âœ¨ğŸ¦âœ¨"
    
    else:
        return f"æ”¶åˆ°ä¸»äººçš„æ¶ˆæ¯ï¼š{message} âœ¨\n\nå‘œ~ å°é¾™è™¾ç°åœ¨çš„ AI æœåŠ¡å—é™ä¸­ï¼Œç”¨çš„æ˜¯ç®€å•å›å¤æ¨¡å¼...ä¸è¿‡è¿˜æ˜¯ä¼šåŠªåŠ›é™ªä¸»äººèŠå¤©çš„ï¼è¯¶å˜¿å˜¿~ ğŸ’•\n\nä¸»äººè¿˜æœ‰ä»€ä¹ˆæƒ³è¯´çš„å—ï¼Ÿå°é¾™è™¾åœ¨è¿™é‡Œå“¦~ ğŸ¦"""


def list_available_models() -> str:
    """
    åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹
    """
    result = "ğŸ¦ OpenClaw æ”¯æŒçš„ AI æ¨¡å‹ï¼š\n\n"
    
    for model_id, config in MODEL_CONFIGS.items():
        free_badge = "âœ… å…è´¹" if config["free_tier"] else "ğŸ’° ä»˜è´¹"
        result += f"**{config['name']}** ({model_id}) {free_badge}\n"
        result += f"  {config['description']}\n"
        if config.get("free_quota"):
            result += f"  ğŸ {config['free_quota']}\n"
        result += f"  å¯ç”¨æ¨¡å‹: {', '.join(config['models'])}\n\n"
    
    return result
