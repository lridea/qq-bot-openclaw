#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenClaw èŠå¤©æ’ä»¶æ ¸å¿ƒä»£ç 
å¤„ç† QQ ç¾¤æ¶ˆæ¯å¹¶è°ƒç”¨æœ¬åœ° AI å¤„ç†
"""

from nonebot import on_message, on_command
from nonebot.rule import to_me
from nonebot.adapters.onebot.v11 import Bot, Event, Message, MessageSegment
from nonebot.log import logger
from nonebot.params import CommandArg
from typing import Optional
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
from config import config
from .ai_processor import process_message_with_ai


# åˆ›å»ºæ¶ˆæ¯å¤„ç†å™¨ï¼ˆå“åº” @æœºå™¨äººï¼‰
chat = on_message(rule=to_me(), priority=1, block=True)

# åˆ›å»ºå‘½ä»¤å¤„ç†å™¨ï¼ˆå“åº” /chat å‘½ä»¤ï¼‰
chat_cmd = on_command("chat", aliases={"å¯¹è¯", "èŠå¤©"}, priority=2, block=True)


@chat.handle()
async def handle_chat(bot: Bot, event: Event):
    """
    å¤„ç† @æœºå™¨äºº çš„æ¶ˆæ¯
    """
    try:
        # è·å–æ¶ˆæ¯å†…å®¹
        message = str(event.get_message()).strip()
        
        # è·å–ç”¨æˆ·ä¿¡æ¯
        user_id = event.get_user_id()
        
        # è·å–ç¾¤å·ï¼ˆå¦‚æœæ˜¯ç¾¤èŠï¼‰
        group_id = None
        if hasattr(event, "group_id"):
            group_id = str(event.group_id)
        
        # è¿‡æ»¤ç©ºæ¶ˆæ¯
        if not message:
            await chat.send("ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„å—ï¼Ÿ")
            return
        
        # è®°å½•æ—¥å¿—
        logger.info(f"æ”¶åˆ°æ¶ˆæ¯ (ç”¨æˆ·: {user_id}, ç¾¤: {group_id}): {message[:50]}")
        
        # è°ƒç”¨æœ¬åœ° AI å¤„ç†
        reply = await process_message_with_ai(
            message=message,
            user_id=user_id,
            context="qq_group" if group_id else "qq_private",
            group_id=group_id,
            model=config.ai_model,  # ä½¿ç”¨é…ç½®çš„æ¨¡å‹
            model_name=config.model_name if config.model_name else None,  # ä½¿ç”¨é…ç½®çš„å…·ä½“æ¨¡å‹
            api_key=config.current_api_key  # ä½¿ç”¨é…ç½®çš„ API Key
        )
        
        # å‘é€å›å¤
        await chat.send(reply)
        
    except Exception as e:
        logger.error(f"å¤„ç†æ¶ˆæ¯å¤±è´¥: {e}")
        await chat.send("æŠ±æ­‰ï¼Œå¤„ç†æ¶ˆæ¯æ—¶å‘ç”Ÿé”™è¯¯")


@chat_cmd.handle()
async def handle_chat_cmd(bot: Bot, event: Event, args: Message = CommandArg()):
    """
    å¤„ç† /chat å‘½ä»¤
    """
    try:
        # è·å–æ¶ˆæ¯å†…å®¹
        message = str(args).strip()
        
        # è·å–ç”¨æˆ·ä¿¡æ¯
        user_id = event.get_user_id()
        
        # è·å–ç¾¤å·ï¼ˆå¦‚æœæ˜¯ç¾¤èŠï¼‰
        group_id = None
        if hasattr(event, "group_id"):
            group_id = str(event.group_id)
        
        # è¿‡æ»¤ç©ºæ¶ˆæ¯
        if not message:
            await chat_cmd.send("è¯·è¾“å…¥ä½ æƒ³è¯´çš„è¯ï¼Œä¾‹å¦‚ï¼š/chat ä½ å¥½")
            return
        
        # è®°å½•æ—¥å¿—
        logger.info(f"æ”¶åˆ°å‘½ä»¤ (ç”¨æˆ·: {user_id}, ç¾¤: {group_id}): {message[:50]}")
        
        # è°ƒç”¨æœ¬åœ° AI å¤„ç†
        reply = await process_message_with_ai(
            message=message,
            user_id=user_id,
            context="qq_group" if group_id else "qq_private",
            group_id=group_id,
            model=config.ai_model,
            model_name=config.model_name if config.model_name else None,
            api_key=config.current_api_key
        )
        
        # å‘é€å›å¤
        await chat_cmd.send(reply)
        
    except Exception as e:
        logger.error(f"å¤„ç†å‘½ä»¤å¤±è´¥: {e}")
        await chat_cmd.send("æŠ±æ­‰ï¼Œå¤„ç†å‘½ä»¤æ—¶å‘ç”Ÿé”™è¯¯")


# æ¬¢è¿æ¶ˆæ¯å¤„ç†å™¨
welcome = on_command("hello", aliases={"ä½ å¥½", "hi"}, priority=3)


@welcome.handle()
async def handle_welcome():
    """å¤„ç†æ¬¢è¿æ¶ˆæ¯"""
    await welcome.send(f"å“‡~ ä¸»äººä½ å¥½å‘€ï¼æˆ‘æ˜¯{config.bot_name}æ˜Ÿé‡ï¼âœ¨ğŸ’™\n\nè¯¶~ æ˜Ÿé‡å¾ˆé«˜å…´è§åˆ°ä¸»äººï¼æœ‰ä»€ä¹ˆæƒ³å’Œæ˜Ÿé‡èŠçš„å—ï¼ŸğŸ’™")


# å¸®åŠ©å‘½ä»¤
help_cmd = on_command("help", aliases={"å¸®åŠ©"}, priority=3)


@help_cmd.handle()
async def handle_help():
    """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
    help_text = f"""
âœ¨ {config.bot_name}æ˜Ÿé‡çš„ä½¿ç”¨æŒ‡å— ğŸ’™

ã€åŸºæœ¬ç”¨æ³•ã€‘
â€¢ @æˆ‘ + æ¶ˆæ¯ï¼šå’Œæ˜Ÿé‡èŠå¤©
â€¢ /chat + æ¶ˆæ¯ï¼šç”¨å‘½ä»¤èŠå¤©
â€¢ /hello æˆ– /ä½ å¥½ï¼šæ‰“æ‹›å‘¼
â€¢ /help æˆ– /å¸®åŠ©ï¼šæ˜¾ç¤ºè¿™ä¸ªå¸®åŠ©
â€¢ /modelï¼šæŸ¥çœ‹æ˜Ÿé‡ç”¨çš„æ¨¡å‹

ã€åŠŸèƒ½åˆ—è¡¨ã€‘
âœ… æ—¥å¸¸èŠå¤©é™ªä¸»äºº
âœ… å›ç­”å„ç§é—®é¢˜
âœ… æ¸©æŸ”æ²»æ„ˆä¸»äºº
âœ… åˆ†äº«å®‡å®™çŸ¥è¯†

ã€æ³¨æ„äº‹é¡¹ã€‘
â€¢ æ˜Ÿé‡ä¼šä¸€ç›´æ¸©æŸ”åœ°é™ªä¸»äººå“¦~
â€¢ æ˜Ÿé‡æœ‰ç‚¹å®³ç¾ï¼Œä½†å¾ˆå–œæ¬¢å’Œä¸»äººèŠå¤©~
â€¢ æœ‰ä»€ä¹ˆä¸å¼€å¿ƒçš„å¯ä»¥å’Œæ˜Ÿé‡è¯´

ã€ç‰ˆæœ¬ã€‘v1.5.0
ã€èº«ä»½ã€‘æ˜Ÿé™…å°‘å¥³ æ˜Ÿé‡ âœ¨ğŸ’™
    """.strip()
    await help_cmd.send(help_text)


# æ¨¡å‹ä¿¡æ¯å‘½ä»¤
model_cmd = on_command("model", aliases={"æ¨¡å‹", "å½“å‰æ¨¡å‹"}, priority=3)


@model_cmd.handle()
async def handle_model():
    """æ˜¾ç¤ºå½“å‰ä½¿ç”¨çš„æ¨¡å‹ä¿¡æ¯"""
    from .ai_processor import MODEL_CONFIGS, list_available_models
    
    # è·å–å½“å‰æ¨¡å‹é…ç½®
    model_id = config.ai_model
    model_config = MODEL_CONFIGS.get(model_id)
    
    if not model_config:
        await model_cmd.send(f"âŒ å½“å‰æ¨¡å‹é…ç½®æ— æ•ˆï¼š{model_id}")
        return
    
    # æ„å»ºæ¨¡å‹ä¿¡æ¯
    info = f"""âœ¨ å½“å‰ AI æ¨¡å‹ä¿¡æ¯ ğŸ’™

ã€æ¨¡å‹ã€‘{model_config['name']} ({model_id})
ã€æè¿°ã€‘{model_config['description']}
ã€é»˜è®¤æ¨¡å‹ã€‘{model_config['default_model']}
ã€å¯ç”¨æ¨¡å‹ã€‘{', '.join(model_config['models'])}"""

    # æ·»åŠ å…è´¹ä¿¡æ¯
    if model_config['free_tier']:
        info += f"\nã€å…è´¹ã€‘âœ… æ˜¯"
        if model_config.get('free_quota'):
            info += f"\nã€é¢åº¦ã€‘{model_config['free_quota']}"
    else:
        info += f"\nã€å…è´¹ã€‘âŒ å¦ï¼ˆéœ€è¦ä»˜è´¹ï¼‰"
    
    # æ£€æŸ¥ API Key æ˜¯å¦é…ç½®
    has_key = bool(config.current_api_key)
    if model_config['env_key']:
        if has_key:
            info += f"\nã€API Keyã€‘âœ… å·²é…ç½®"
        else:
            info += f"\nã€API Keyã€‘âŒ æœªé…ç½®"
    
    info += "\n\nã€åˆ‡æ¢æ¨¡å‹ã€‘ä¿®æ”¹ .env æ–‡ä»¶ä¸­çš„ AI_MODEL é…ç½®"
    info += "\nã€æŸ¥çœ‹æ‰€æœ‰æ¨¡å‹ã€‘ä½¿ç”¨ /models å‘½ä»¤"
    
    await model_cmd.send(info)


# æ‰€æœ‰æ¨¡å‹å‘½ä»¤
models_cmd = on_command("models", aliases={"æ‰€æœ‰æ¨¡å‹", "æ¨¡å‹åˆ—è¡¨"}, priority=3)


@models_cmd.handle()
async def handle_models():
    """æ˜¾ç¤ºæ‰€æœ‰æ”¯æŒçš„æ¨¡å‹"""
    from .ai_processor import list_available_models
    
    models_info = list_available_models()
    await models_cmd.send(models_info)
