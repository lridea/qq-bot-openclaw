#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenClaw èŠå¤©æ’ä»¶æ ¸å¿ƒä»£ç 
å¤„ç† QQ ç¾¤æ¶ˆæ¯å¹¶è°ƒç”¨æœ¬åœ° AI å¤„ç†
"""

from nonebot import on_message, on_command
from nonebot.rule import to_me
from nonebot.adapters.onebot.v11 import Bot, Event, Message, MessageSegment
from nonebot.log import logger
from nonebot.params import CommandArg
from typing import Optional
from nonebot.permission import SUPERUSER
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
from config import config
from .ai_processor import process_message_with_ai


# åˆ›å»ºæ¶ˆæ¯å¤„ç†å™¨ï¼ˆå“åº” @æœºå™¨äººï¼‰
chat = on_message(rule=to_me(), priority=1, block=True)

# åˆ›å»ºå‘½ä»¤å¤„ç†å™¨ï¼ˆå“åº” /chat å‘½ä»¤ï¼‰
chat_cmd = on_command("chat", aliases={"å¯¹è¯", "èŠå¤©"}, priority=2, block=True)


@chat.handle()
async def handle_chat(bot: Bot, event: Event):
    """
    å¤„ç† @æœºå™¨äºº çš„æ¶ˆæ¯
    """
    try:
        # è·å–æ¶ˆæ¯å†…å®¹
        message = str(event.get_message()).strip()
        
        # è·å–ç”¨æˆ·ä¿¡æ¯
        user_id = event.get_user_id()
        
        # è·å–ç¾¤å·ï¼ˆå¦‚æœæ˜¯ç¾¤èŠï¼‰
        group_id = None
        if hasattr(event, "group_id"):
            group_id = str(event.group_id)
        
        # è¿‡æ»¤ç©ºæ¶ˆæ¯
        if not message:
            await chat.send("ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„å—ï¼Ÿ")
            return
        
        # è®°å½•æ—¥å¿—
        logger.info(f"æ”¶åˆ°æ¶ˆæ¯ (ç”¨æˆ·: {user_id}, ç¾¤: {group_id}): {message[:50]}")
        
        # ========== å›¾ç‰‡è¯†åˆ«åŠŸèƒ½ ==========
        # æ£€æµ‹æ¶ˆæ¯ä¸­æ˜¯å¦æœ‰å›¾ç‰‡
        from .image_processor import extract_image_from_message
        from .vision_client import VisionAIClient
        
        image_data = await extract_image_from_message(bot, event)
        
        if image_data and image_data.has_data():
            # æœ‰å›¾ç‰‡ï¼Œä½¿ç”¨ Vision AI è¯†åˆ«
            logger.info("ğŸ“¸ æ£€æµ‹åˆ°å›¾ç‰‡ï¼Œå¯åŠ¨ Vision AI è¯†åˆ«...")
            
            # è·å– Vision æ¨¡å‹é…ç½®
            vision_model = config.model_name or "gpt-4o-mini"
            
            # åˆ›å»º Vision AI å®¢æˆ·ç«¯
            vision_client = VisionAIClient(
                api_key=config.current_api_key,
                provider=config.ai_model,
                base_url=None  # ä½¿ç”¨é»˜è®¤ URL
            )
            
            # è¯†åˆ«å›¾ç‰‡
            prompt = f"è¯·è¯†åˆ«è¿™å¼ å›¾ç‰‡ï¼Œå¹¶ç»“åˆç”¨æˆ·çš„é—®é¢˜å›ç­”ï¼š{message}" if message else "è¯·æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹"
            reply = await vision_client.recognize_image(
                image_data=image_data,
                prompt=prompt,
                model=vision_model
            )
            
            # å‘é€å›å¤
            await chat.send(reply)
            return
        
        # ========== æ™®é€šæ–‡æœ¬å¯¹è¯ ==========
        # è°ƒç”¨æœ¬åœ° AI å¤„ç†
        reply = await process_message_with_ai(
            message=message,
            user_id=user_id,
            context="qq_group" if group_id else "qq_private",
            group_id=group_id,
            model=config.ai_model,  # ä½¿ç”¨é…ç½®çš„æ¨¡å‹
            model_name=config.model_name if config.model_name else None,  # ä½¿ç”¨é…ç½®çš„å…·ä½“æ¨¡å‹
            api_key=config.current_api_key  # ä½¿ç”¨é…ç½®çš„ API Key
        )
        
        # å‘é€å›å¤
        await chat.send(reply)
        
    except Exception as e:
        logger.error(f"å¤„ç†æ¶ˆæ¯å¤±è´¥: {e}")
        await chat.send("æŠ±æ­‰ï¼Œå¤„ç†æ¶ˆæ¯æ—¶å‘ç”Ÿé”™è¯¯")


@chat_cmd.handle()
async def handle_chat_cmd(bot: Bot, event: Event, args: Message = CommandArg()):
    """
    å¤„ç† /chat å‘½ä»¤
    """
    try:
        # è·å–æ¶ˆæ¯å†…å®¹
        message = str(args).strip()
        
        # è·å–ç”¨æˆ·ä¿¡æ¯
        user_id = event.get_user_id()
        
        # è·å–ç¾¤å·ï¼ˆå¦‚æœæ˜¯ç¾¤èŠï¼‰
        group_id = None
        if hasattr(event, "group_id"):
            group_id = str(event.group_id)
        
        # è¿‡æ»¤ç©ºæ¶ˆæ¯
        if not message:
            await chat_cmd.send("è¯·è¾“å…¥ä½ æƒ³è¯´çš„è¯ï¼Œä¾‹å¦‚ï¼š/chat ä½ å¥½")
            return
        
        # è®°å½•æ—¥å¿—
        logger.info(f"æ”¶åˆ°å‘½ä»¤ (ç”¨æˆ·: {user_id}, ç¾¤: {group_id}): {message[:50]}")
        
        # è°ƒç”¨æœ¬åœ° AI å¤„ç†
        reply = await process_message_with_ai(
            message=message,
            user_id=user_id,
            context="qq_group" if group_id else "qq_private",
            group_id=group_id,
            model=config.ai_model,
            model_name=config.model_name if config.model_name else None,
            api_key=config.current_api_key
        )
        
        # å‘é€å›å¤
        await chat_cmd.send(reply)
        
    except Exception as e:
        logger.error(f"å¤„ç†å‘½ä»¤å¤±è´¥: {e}")
        await chat_cmd.send("æŠ±æ­‰ï¼Œå¤„ç†å‘½ä»¤æ—¶å‘ç”Ÿé”™è¯¯")


# æ¬¢è¿æ¶ˆæ¯å¤„ç†å™¨
welcome = on_command("hello", aliases={"ä½ å¥½", "hi"}, priority=3)


@welcome.handle()
async def handle_welcome():
    """å¤„ç†æ¬¢è¿æ¶ˆæ¯"""
    await welcome.send(f"å“‡~ ä¸»äººä½ å¥½å‘€ï¼æˆ‘æ˜¯{config.bot_name}æ˜Ÿé‡ï¼âœ¨ğŸ’™\n\nè¯¶~ æ˜Ÿé‡å¾ˆé«˜å…´è§åˆ°ä¸»äººï¼æœ‰ä»€ä¹ˆæƒ³å’Œæ˜Ÿé‡èŠçš„å—ï¼ŸğŸ’™")


# å¸®åŠ©å‘½ä»¤
help_cmd = on_command("help", aliases={"å¸®åŠ©"}, priority=3)


@help_cmd.handle()
async def handle_help():
    """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
    help_text = f"""
âœ¨ {config.bot_name}æ˜Ÿé‡çš„ä½¿ç”¨æŒ‡å— ğŸ’™

ã€åŸºæœ¬ç”¨æ³•ã€‘
â€¢ @æˆ‘ + æ¶ˆæ¯ï¼šå’Œæ˜Ÿé‡èŠå¤©
â€¢ /chat + æ¶ˆæ¯ï¼šç”¨å‘½ä»¤èŠå¤©
â€¢ /hello æˆ– /ä½ å¥½ï¼šæ‰“æ‹›å‘¼
â€¢ /help æˆ– /å¸®åŠ©ï¼šæ˜¾ç¤ºè¿™ä¸ªå¸®åŠ©
â€¢ /modelï¼šæŸ¥çœ‹æ˜Ÿé‡ç”¨çš„æ¨¡å‹

ã€åŠŸèƒ½åˆ—è¡¨ã€‘
âœ… æ—¥å¸¸èŠå¤©é™ªä¸»äºº
âœ… å›ç­”å„ç§é—®é¢˜
âœ… æ¸©æŸ”æ²»æ„ˆä¸»äºº
âœ… åˆ†äº«å®‡å®™çŸ¥è¯†

ã€æ³¨æ„äº‹é¡¹ã€‘
â€¢ æ˜Ÿé‡ä¼šä¸€ç›´æ¸©æŸ”åœ°é™ªä¸»äººå“¦~
â€¢ æ˜Ÿé‡æœ‰ç‚¹å®³ç¾ï¼Œä½†å¾ˆå–œæ¬¢å’Œä¸»äººèŠå¤©~
â€¢ æœ‰ä»€ä¹ˆä¸å¼€å¿ƒçš„å¯ä»¥å’Œæ˜Ÿé‡è¯´

ã€ç‰ˆæœ¬ã€‘v1.5.0
ã€èº«ä»½ã€‘æ˜Ÿé™…å°‘å¥³ æ˜Ÿé‡ âœ¨ğŸ’™
    """.strip()
    await help_cmd.send(help_text)


# æ¨¡å‹ä¿¡æ¯å‘½ä»¤
model_cmd = on_command("model", aliases={"æ¨¡å‹", "å½“å‰æ¨¡å‹"}, priority=3)


@model_cmd.handle()
async def handle_model():
    """æ˜¾ç¤ºå½“å‰ä½¿ç”¨çš„æ¨¡å‹ä¿¡æ¯"""
    from .ai_processor import MODEL_CONFIGS, list_available_models
    
    # è·å–å½“å‰æ¨¡å‹é…ç½®
    model_id = config.ai_model
    model_config = MODEL_CONFIGS.get(model_id)
    
    if not model_config:
        await model_cmd.send(f"âŒ å½“å‰æ¨¡å‹é…ç½®æ— æ•ˆï¼š{model_id}")
        return
    
    # æ„å»ºæ¨¡å‹ä¿¡æ¯
    info = f"""âœ¨ å½“å‰ AI æ¨¡å‹ä¿¡æ¯ ğŸ’™

ã€æ¨¡å‹ã€‘{model_config['name']} ({model_id})
ã€æè¿°ã€‘{model_config['description']}
ã€é»˜è®¤æ¨¡å‹ã€‘{model_config['default_model']}
ã€å¯ç”¨æ¨¡å‹ã€‘{', '.join(model_config['models'])}"""

    # æ·»åŠ å…è´¹ä¿¡æ¯
    if model_config['free_tier']:
        info += f"\nã€å…è´¹ã€‘âœ… æ˜¯"
        if model_config.get('free_quota'):
            info += f"\nã€é¢åº¦ã€‘{model_config['free_quota']}"
    else:
        info += f"\nã€å…è´¹ã€‘âŒ å¦ï¼ˆéœ€è¦ä»˜è´¹ï¼‰"
    
    # æ£€æŸ¥ API Key æ˜¯å¦é…ç½®
    has_key = bool(config.current_api_key)
    if model_config['env_key']:
        if has_key:
            info += f"\nã€API Keyã€‘âœ… å·²é…ç½®"
        else:
            info += f"\nã€API Keyã€‘âŒ æœªé…ç½®"
    
    info += "\n\nã€åˆ‡æ¢æ¨¡å‹ã€‘ä¿®æ”¹ .env æ–‡ä»¶ä¸­çš„ AI_MODEL é…ç½®"
    info += "\nã€æŸ¥çœ‹æ‰€æœ‰æ¨¡å‹ã€‘ä½¿ç”¨ /models å‘½ä»¤"
    
    await model_cmd.send(info)


# æ‰€æœ‰æ¨¡å‹å‘½ä»¤
models_cmd = on_command("models", aliases={"æ‰€æœ‰æ¨¡å‹", "æ¨¡å‹åˆ—è¡¨"}, priority=3)


@models_cmd.handle()
async def handle_models():
    """æ˜¾ç¤ºæ‰€æœ‰æ”¯æŒçš„æ¨¡å‹"""
    from .ai_processor import list_available_models
    
    models_info = list_available_models()
    await models_cmd.send(models_info)


# ========== è¶…çº§ç®¡ç†å‘˜ä¸“ç”¨å‘½ä»¤ ==========

from nonebot.permission import SUPERUSER

# çŠ¶æ€å‘½ä»¤
status_cmd = on_command("status", aliases={"çŠ¶æ€"}, priority=1, permission=SUPERUSER)


@status_cmd.handle()
async def handle_status():
    """æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€ï¼ˆä»…è¶…çº§ç®¡ç†å‘˜ï¼‰"""
    from .ai_processor import MODEL_CONFIGS
    
    # è·å–å½“å‰æ¨¡å‹é…ç½®
    model_config = MODEL_CONFIGS.get(config.ai_model)
    
    status_text = f"""âœ¨ æ˜Ÿé‡ç³»ç»ŸçŠ¶æ€ ğŸ’™

ã€é…ç½®ä¿¡æ¯ã€‘
â€¢ æœºå™¨äººåç§°ï¼š{config.bot_name}
â€¢ å½“å‰æ¨¡å‹ï¼š{config.ai_model}
â€¢ å½“å‰æ¨¡å‹åç§°ï¼š{config.model_name or model_config['default_model'] if model_config else 'æœªçŸ¥'}
â€¢ æ¨¡å‹æè¿°ï¼š{model_config['description'] if model_config else 'æœªçŸ¥'}

ã€AI é…ç½®ã€‘
â€¢ API Key å·²é…ç½®ï¼šâœ… æ˜¯" if config.current_api_key else "âŒ å¦"
â€¢ ä¼šè¯è¶…æ—¶ï¼š{config.session_expire_timeout} ç§’

ã€è¿è¡Œé…ç½®ã€‘
â€¢ ç›‘å¬åœ°å€ï¼š{config.host}:{config.port}
â€¢ NapCat åœ°å€ï¼š{config.napcat_ws_url}
â€¢ è¶…çº§ç®¡ç†å‘˜ï¼š{len(config.superusers)} ä½

ã€ç³»ç»Ÿä¿¡æ¯ã€‘
â€¢ Python ç‰ˆæœ¬ï¼š{sys.version.split()[0]}
â€¢ è¿è¡Œç¯å¢ƒï¼š{'Windows' if sys.platform == 'win32' else 'Linux' if sys.platform.startswith('linux') else 'macOS'}
â€¢ æ—¥å¿—çº§åˆ«ï¼š{config.log_level}

âœ¨ ç³»ç»Ÿè¿è¡Œæ­£å¸¸ ğŸ’™
"""
    await status_cmd.send(status_text)


# åˆ‡æ¢æ¨¡å‹å‘½ä»¤
switch_model_cmd = on_command("switch", aliases={"åˆ‡æ¢æ¨¡å‹"}, priority=1, permission=SUPERUSER)


@switch_model_cmd.handle()
async def handle_switch_model(args: Message = CommandArg()):
    """åˆ‡æ¢ AI æ¨¡å‹ï¼ˆä»…è¶…çº§ç®¡ç†å‘˜ï¼‰"""
    from .ai_processor import MODEL_CONFIGS
    
    # è·å–å‚æ•°
    new_model = str(args).strip().lower()
    
    if not new_model:
        # æ˜¾ç¤ºå¯åˆ‡æ¢çš„æ¨¡å‹åˆ—è¡¨
        available = list(MODEL_CONFIGS.keys())
        text = "âœ¨ å¯åˆ‡æ¢çš„ AI æ¨¡å‹åˆ—è¡¨ ğŸ’™\n\n"
        for model_id in available:
            model_config = MODEL_CONFIGS[model_id]
            current_mark = "âœ“ å½“å‰" if model_id == config.ai_model else ""
            text += f"â€¢ {model_config['name']} ({model_id}) {current_mark}\n"
        await switch_model_cmd.send(text)
        return
    
    # éªŒè¯æ¨¡å‹
    if new_model not in MODEL_CONFIGS:
        await switch_model_cmd.send(f"âŒ æ¨¡å‹ '{new_model}' ä¸å­˜åœ¨\n\nå¯ç”¨æ¨¡å‹ï¼š{', '.join(MODEL_CONFIGS.keys())}")
        return
    
    # åˆ‡æ¢æ¨¡å‹
    old_model = config.ai_model
    config.ai_model = new_model
    
    model_config = MODEL_CONFIGS[new_model]
    await switch_model_cmd.send(f"âœ… æ¨¡å‹åˆ‡æ¢æˆåŠŸ\n\nâ€¢ ä»ï¼š{old_model}\nâ€¢ åˆ°ï¼š{new_model} ({model_config['name']})\n\nâœ¨ å·²ç”Ÿæ•ˆ ğŸ’™")


# è®¾ç½®å…·ä½“æ¨¡å‹å‘½ä»¤
set_model_cmd = on_command("set_model", aliases={"è®¾ç½®æ¨¡å‹"}, priority=1, permission=SUPERUSER)


@set_model_cmd.handle()
async def handle_set_model(args: Message = CommandArg()):
    """è®¾ç½®å…·ä½“çš„ AI æ¨¡å‹ï¼ˆä»…è¶…çº§ç®¡ç†å‘˜ï¼‰"""
    from .ai_processor import MODEL_CONFIGS
    
    # è·å–å‚æ•°
    new_model_name = str(args).strip()
    
    if not new_model_name:
        await set_model_cmd.send(f"âŒ è¯·æŒ‡å®šæ¨¡å‹åç§°\n\nä¾‹å¦‚ï¼š/set_model gpt-4o-mini\n\nä½¿ç”¨ /models æŸ¥çœ‹æ‰€æœ‰å¯ç”¨æ¨¡å‹")
        return
    
    # éªŒè¯æ¨¡å‹æ˜¯å¦åœ¨å½“å‰ä¾›åº”å•†çš„æ¨¡å‹åˆ—è¡¨ä¸­
    model_config = MODEL_CONFIGS.get(config.ai_model)
    if not model_config:
        await set_model_cmd.send(f"âŒ å½“å‰ä¾›åº”å•† {config.ai_model} ä¸å­˜åœ¨")
        return
    
    if new_model_name not in model_config['models']:
        await set_model_cmd.send(f"âŒ æ¨¡å‹ '{new_model_name}' ä¸åœ¨ {model_config['name']} çš„æ”¯æŒåˆ—è¡¨ä¸­\n\nä½¿ç”¨ /models æŸ¥çœ‹æ‰€æœ‰å¯ç”¨æ¨¡å‹")
        return
    
    # è®¾ç½®æ¨¡å‹
    old_model_name = config.model_name or model_config['default_model']
    config.model_name = new_model_name
    
    await set_model_cmd.send(f"âœ… æ¨¡å‹è®¾ç½®æˆåŠŸ\n\nâ€¢ ä¾›åº”å•†ï¼š{config.ai_model} ({model_config['name']})\nâ€¢ ä»ï¼š{old_model_name}\nâ€¢ åˆ°ï¼š{new_model_name}\n\nâœ¨ å·²ç”Ÿæ•ˆ ğŸ’™")


# é‡å¯å‘½ä»¤
restart_cmd = on_command("restart", aliases={"é‡å¯"}, priority=1, permission=SUPERUSER)


@restart_cmd.handle()
async def handle_restart():
    """é‡å¯æœºå™¨äººï¼ˆä»…è¶…çº§ç®¡ç†å‘˜ï¼‰"""
    await restart_cmd.send("ğŸ”„ æ­£åœ¨é‡å¯æ˜Ÿé‡... âœ¨ğŸ’™\n\nâ±ï¸ è¯·ç¨ç­‰ç‰‡åˆ»...")
    
    # ä¿å­˜è®°å½•
    logger.info(f"è¶…çº§ç®¡ç†å‘˜ {config.superusers} è¯·æ±‚é‡å¯æœºå™¨äºº")
    
    # è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„é‡å¯é€»è¾‘
    # ç›®å‰åªå‘é€æç¤ºæ¶ˆæ¯
    await restart_cmd.send("ğŸ’¡ æç¤ºï¼šè¯·åœ¨ç»ˆç«¯ä¸­æ‰‹åŠ¨é‡å¯æœºå™¨äºº\n\nbash start.sh")


# ç®¡ç†å‘˜å¸®åŠ©å‘½ä»¤
admin_help_cmd = on_command("admin", aliases={"ç®¡ç†å‘˜å¸®åŠ©"}, priority=1, permission=SUPERUSER)


@admin_help_cmd.handle()
async def handle_admin_help():
    """æ˜¾ç¤ºç®¡ç†å‘˜å‘½ä»¤å¸®åŠ©ï¼ˆä»…è¶…çº§ç®¡ç†å‘˜ï¼‰"""
    help_text = """
ğŸ” è¶…çº§ç®¡ç†å‘˜å‘½ä»¤åˆ—è¡¨ âœ¨ğŸ’™

ã€ç³»ç»Ÿç®¡ç†ã€‘
â€¢ /status æˆ– /çŠ¶æ€ - æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€
â€¢ /restart æˆ– /é‡å¯ - é‡å¯æœºå™¨äºº

ã€æ¨¡å‹ç®¡ç†ã€‘
â€¢ /switch æˆ– /åˆ‡æ¢æ¨¡å‹ - åˆ‡æ¢ AI ä¾›åº”å•†
  â€¢ /switch siliconflow - åˆ‡æ¢åˆ°ç¡…åŸºæµåŠ¨
  â€¢ /switch deepseek - åˆ‡æ¢åˆ° DeepSeek
â€¢ /set_model æˆ– /è®¾ç½®æ¨¡å‹ - è®¾ç½®å…·ä½“æ¨¡å‹
  â€¢ /set_model gpt-4o-mini - è®¾ç½®ä¸º GPT-4o-mini
  â€¢ /set_model glm-4.7 - è®¾ç½®ä¸º GLM-4.7

ã€ä¿¡æ¯æŸ¥è¯¢ã€‘
â€¢ /models - æŸ¥çœ‹æ‰€æœ‰å¯ç”¨æ¨¡å‹
â€¢ /model - æŸ¥çœ‹å½“å‰æ¨¡å‹ä¿¡æ¯

ã€æƒé™è¯´æ˜ã€‘
âš ï¸ ä»¥ä¸Šå‘½ä»¤ä»…è¶…çº§ç®¡ç†å‘˜å¯ä»¥ä½¿ç”¨
ğŸ“ è¶…çº§ç®¡ç†å‘˜é…ç½®åœ¨ .env æ–‡ä»¶çš„ SUPERUSERS

ğŸ’¡ æç¤ºï¼šä½¿ç”¨ /help æŸ¥çœ‹æ‰€æœ‰å‘½ä»¤
"""
    await admin_help_cmd.send(help_text)


